# M√≥dulo 07-C: Clasificaci√≥n con Features Auto-Seleccionadas

## üìã Descripci√≥n

Este m√≥dulo consume **autom√°ticamente** las caracter√≠sticas seleccionadas por el m√≥dulo 06-C, eliminando la necesidad de configuraci√≥n manual.

### ‚ö° Funcionalidad: Evaluaci√≥n de M√∫ltiples Subsets

**07-C ahora eval√∫a autom√°ticamente m√∫ltiples configuraciones**:
- ‚úÖ **TOP_5**: Las 5 caracter√≠sticas m√°s discriminativas
- ‚úÖ **TOP_10**: Las 10 caracter√≠sticas m√°s discriminativas
- ‚úÖ **ALL_SELECTED**: Todas las seleccionadas por 06-C (15)
- ‚úÖ **Por descriptor**: Subsets de cada tipo (lbp_only, stat_only, wavelet_only)

**Resultado**: Comparaci√≥n autom√°tica para encontrar el **subset √≥ptimo**.

---

## üîó Conexi√≥n Autom√°tica con 06-C

### **C√≥mo Funciona**

```python
# config.py l√≠nea 33-49

def load_selected_features():
    """
    Carga autom√°ticamente las caracter√≠sticas seleccionadas por 06-C.
    """
    json_path = Path('../06-C_Feature_Selection/output/feature_ranking.json')

    if not json_path.exists():
        raise FileNotFoundError(
            "Ejecuta primero: python 06-C_Feature_Selection/main.py"
        )

    with open(json_path, 'r') as f:
        data = json.load(f)

    # Extraer nombres de caracter√≠sticas
    feature_names = [feat['name'] for feat in data['selected_features']]

    # Generar subsets autom√°ticamente
    FEATURE_SUBSETS = {
        'top_5': feature_names[:5],
        'top_10': feature_names[:10],
        'all_selected': feature_names
    }

    return feature_names, FEATURE_SUBSETS
```

### **Al Importar config.py**

```bash
$ python
>>> import config

‚úì Caracter√≠sticas cargadas autom√°ticamente desde 06-C (m7_tau9):
  - Total: 15 caracter√≠sticas
  - Configuraci√≥n: Œ±=0.05, Cohen's d‚â•0.2, r<0.85
```

**No necesitas editar nada. Todo autom√°tico.**

---

## üöÄ Uso del M√≥dulo

### **Prerequisito**

```bash
# DEBES ejecutar 06-C primero para generar feature_ranking.json
cd 06-C_Feature_Selection
python main.py

# Verifica que existe el JSON
ls 06-C_Feature_Selection/output/feature_ranking.json
```

### **Ejecuci√≥n**

```bash
cd 07-C_Classification

# Evaluar TODOS los subsets autom√°ticamente (Recomendado)
python main.py

# Output:
# ================================================================================
# EVALUANDO SUBSET: TOP_5 (5 caracter√≠sticas)
# ================================================================================
# ... entrena 8 modelos ...
# üèÜ MEJOR MODELO: Random Forest (F1=0.8060)
#
# ================================================================================
# EVALUANDO SUBSET: TOP_10 (10 caracter√≠sticas)
# ================================================================================
# ... entrena 8 modelos ...
# üèÜ MEJOR MODELO: Random Forest (F1=0.8185)
#
# ================================================================================
# EVALUANDO SUBSET: ALL_SELECTED (15 caracter√≠sticas)
# ================================================================================
# ... entrena 8 modelos ...
# üèÜ MEJOR MODELO: XGBoost (F1=0.8066)
#
# ================================================================================
# COMPARACI√ìN ENTRE SUBSETS DE CARACTER√çSTICAS
# ================================================================================
# Subset                 N Features Mejor Modelo           F1-Score   Accuracy    ROC-AUC
# --------------------------------------------------------------------------------------------
# top_5                           5 random_forest            0.8060     0.8068     0.8401
# top_10                         10 random_forest            0.8185     0.8182     0.9005 ‚≠ê
# all_selected                   15 xgboost                  0.8066     0.8068     0.8823
#
# ================================================================================
# üèÜ MEJOR CONFIGURACI√ìN GLOBAL
# ================================================================================
#   Subset: top_10
#   Modelo: RANDOM_FOREST
#   F1-Score: 0.8185
#   ROC-AUC: 0.9005
# ================================================================================

# Entrenar solo un modelo espec√≠fico (en todos los subsets)
python main.py --model svm

# Sin visualizaciones (solo m√©tricas)
python main.py --no-plots

# Con logging detallado
python main.py --verbose
```

### **Par√°metros CLI Disponibles**

| Par√°metro | Opciones | Default | Descripci√≥n |
|-----------|----------|---------|-------------|
| `--model` | `logistic_regression`, `naive_bayes`, `knn`, `decision_tree`, `svm`, `random_forest`, `neural_network`, `xgboost`, `all` | `all` | Modelo(s) a entrenar |
| `--verbose` / `-v` | - | `False` | Logging detallado |
| `--no-plots` | - | `False` | No generar gr√°ficos (solo m√©tricas) |

---

## üìä Subsets de Caracter√≠sticas Evaluados

El m√≥dulo genera y eval√∫a autom√°ticamente estos subsets:

```python
FEATURE_SUBSETS = {
    'top_5': SELECTED_FEATURES[:5],      # Top 5 por combined score
    'top_10': SELECTED_FEATURES[:10],    # Top 10 por combined score
    'all_selected': SELECTED_FEATURES,   # Todas las seleccionadas (15)

    # Subsets por descriptor (si tienen ‚â•3 caracter√≠sticas)
    'lbp_only': [...],      # Solo caracter√≠sticas LBP
    'stat_only': [...],     # Solo caracter√≠sticas Statistical
    'wavelet_only': [...]   # Solo caracter√≠sticas Wavelet
    'rqa_only': [...],      # Solo caracter√≠sticas RQA (si ‚â•3)
}
```

**Resultado**: Identificaci√≥n autom√°tica del **subset √≥ptimo** (balance entre performance y parsimonia).

---

## üéØ Modelos Implementados

8 clasificadores evaluados en cada subset:

1. **Logistic Regression** - Baseline interpretable (L2 regularization, max_iter=1000)
2. **Naive Bayes** - Modelo probabil√≠stico (Gaussian)
3. **k-NN** - Basado en proximidad (k=5, weights='distance')
4. **Decision Tree** - Reglas interpretables (max_depth=10, min_samples_split=10)
5. **SVM (RBF)** - Captura no linealidades (C=10, gamma='scale', probability=True)
6. **Random Forest** - Ensemble robusto (n_estimators=500, max_depth=15)
7. **Neural Network** - MLP (hidden_layers=(100,50), max_iter=500)
8. **XGBoost** - Gradient boosting (max_depth=6, n_estimators=100, learning_rate=0.1)

---

## üìà Caracter√≠sticas Principales

| Aspecto | Implementaci√≥n |
|---------|----------------|
| **Configuraci√≥n** | ‚úì Autom√°tica desde JSON |
| **Reproducibilidad** | ‚úì Alta (proceso automatizado, random_state=42) |
| **Evaluaci√≥n de subsets** | ‚úì Autom√°tica (TOP_5, TOP_10, ALL_SELECTED) |
| **Identificaci√≥n √≥ptima** | ‚úì Autom√°tica (comparaci√≥n entre subsets) |
| **Actualizaci√≥n** | ‚úì Autom√°tica (re-ejecutar 06-C) |
| **Trazabilidad** | ‚úì Completa (JSON con metadata) |
| **Justificaci√≥n** | ‚úì M√©tricas cient√≠ficas cuantificables |

---

## üìÅ Estructura de Salida

### **Archivos Generados**

```
07-C_Classification/output/
‚îú‚îÄ‚îÄ metrics/
‚îÇ   ‚îú‚îÄ‚îÄ results_20251206_232655.json    # Resultados completos con subsets
‚îÇ   ‚îî‚îÄ‚îÄ plots/
‚îÇ       ‚îú‚îÄ‚îÄ confusion_matrix_*.png      # Matrices por modelo
‚îÇ       ‚îú‚îÄ‚îÄ roc_curve_*.png             # Curvas ROC por modelo
‚îÇ       ‚îú‚îÄ‚îÄ models_metrics_comparison.png
‚îÇ       ‚îú‚îÄ‚îÄ models_f1_comparison.png
‚îÇ       ‚îú‚îÄ‚îÄ models_cv_scores.png
‚îÇ       ‚îî‚îÄ‚îÄ all_models_roc_curves.png
‚îî‚îÄ‚îÄ logs/
    ‚îî‚îÄ‚îÄ classification.log
```

### **Formato del JSON de Resultados**

```json
{
  "timestamp": "2025-12-06T23:26:55",
  "n_samples": 440,
  "n_train": 352,
  "n_test": 88,
  "class_names": ["Normal", "Pathol"],

  "subsets": {
    "top_5": {
      "n_features": 5,
      "features": ["lbp_hist_bin_5_r1_p4", "stat_hist_bin_0", ...],
      "models": [
        {
          "model_name": "random_forest",
          "accuracy": 0.8068,
          "f1_score": 0.8060,
          "roc_auc": 0.8401,
          "cv_f1_mean": 0.7632,
          "cv_f1_std": 0.0696
        },
        ...
      ],
      "best_model": {
        "model_name": "random_forest",
        "f1_score": 0.8060
      }
    },
    "top_10": { ... },
    "all_selected": { ... }
  },

  "best_overall": {
    "subset": "top_10",
    "model_name": "random_forest",
    "accuracy": 0.8182,
    "f1_score": 0.8185,
    "roc_auc": 0.9005
  },

  "selection_config": {
    "alpha": 0.05,
    "min_cohens_d": 0.2,
    "max_correlation": 0.85,
    "target_n_features": 15
  }
}
```

---

## üîç Informaci√≥n Disponible de cada Caracter√≠stica

El JSON de 06-C incluye metadata completa:

```python
# Acceder a metadata de caracter√≠sticas
import config

for feat in config.FEATURE_METADATA:
    print(f"{feat['rank']}. {feat['name']}")
    print(f"   F-Score: {feat['f_score']:.2f}")
    print(f"   p-value: {feat['p_value']:.4f}")
    print(f"   Cohen's d: {feat['cohens_d']:.2f} ({feat['effect_size']})")
    print(f"   MI: {feat['mi_score']:.3f}")
    print(f"   Justificaci√≥n: {feat['justification']}")
```

**Ejemplo de output**:
```
1. lbp_hist_bin_5_r1_p4
   F-Score: 62.60
   p-value: 0.00000
   Cohen's d: 0.76 (medium)
   MI: 0.107
   Justificaci√≥n: altamente significativa (p<0.001), efecto medium (|d|=0.76), alto poder discriminativo
```

---

## üîÑ Flujo Completo de Pipeline

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 05: Extracci√≥n de Descriptores      ‚îÇ
‚îÇ Output: features.csv (181 features) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 06-C: Selecci√≥n Rigurosa (5 fases) ‚îÇ
‚îÇ Output: feature_ranking.json (15)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚Üì (AUTOM√ÅTICO)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 07-C: Clasificaci√≥n Multi-Subset    ‚îÇ
‚îÇ - Carga autom√°tica de JSON          ‚îÇ
‚îÇ - Eval√∫a TOP_5, TOP_10, ALL_SELECTED‚îÇ
‚îÇ - Entrena 8 modelos √ó N subsets     ‚îÇ
‚îÇ - Identifica configuraci√≥n √≥ptima   ‚îÇ
‚îÇ Output: Comparaci√≥n + Mejor subset  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Sin intervenci√≥n manual. Todo automatizado y reproducible.**

---

## üí° Resultados T√≠picos

### **Hallazgos del Experimento TOP_5 vs TOP_10 vs ALL_SELECTED**

Basado en dataset de 440 muestras (239 Normal, 201 Pathol):

| Subset | N Caracter√≠sticas | Mejor Modelo | F1-Score | ROC-AUC | Interpretaci√≥n |
|--------|-------------------|--------------|----------|---------|----------------|
| **TOP_10** üèÜ | **10** | **Random Forest** | **0.8185** | **0.9005** | **√ìptimo: mejor F1 y AUC > 90%** |
| TOP_5 | 5 | Random Forest | 0.8060 | 0.8401 | Parsimonioso pero AUC menor |
| ALL_SELECTED | 15 | XGBoost | 0.8066 | 0.8823 | Buen F1 con m√°s caracter√≠sticas |

**Conclusi√≥n**: 10 caracter√≠sticas es el **punto √≥ptimo** (balance entre parsimonia y performance).

---

## ‚öôÔ∏è Configuraci√≥n Avanzada

### **Usar un JSON Diferente**

Si quieres usar un JSON de selecci√≥n diferente:

```python
# config.py l√≠nea 21
CUSTOM_FEATURE_RANKING = Path('/path/to/other_ranking.json')
```

### **Forzar Caracter√≠sticas Manualmente (No Recomendado)**

Si realmente necesitas overridear:

```python
# config.py despu√©s de la l√≠nea 60
SELECTED_FEATURES = [
    'manual_feature_1',
    'manual_feature_2',
    # ...
]
```

**‚ö†Ô∏è NO RECOMENDADO**: Pierdes trazabilidad y justificaci√≥n cient√≠fica.

---

## üõ†Ô∏è Troubleshooting

### **Error: "No se encontr√≥ feature_ranking.json"**

```bash
# Soluci√≥n: Ejecuta 06-C primero
cd 06-C_Feature_Selection
python main.py

# Verifica que el JSON existe
ls output/feature_ranking.json
```

### **Error: "Caracter√≠stica X no existe en el CSV"**

Significa que el CSV de entrada ha cambiado desde que se ejecut√≥ 06-C.

```bash
# Soluci√≥n: Re-ejecutar 06-C con el CSV actualizado
cd 06-C_Feature_Selection
python main.py --input /path/to/updated_features.csv
```

### **Warning: "Solo X caracter√≠sticas cargadas"**

Si 06-C seleccion√≥ menos de 15 caracter√≠sticas (por restricciones de redundancia):

```bash
# Opci√≥n 1: Relajar threshold en 06-C
# config.py l√≠nea 75
MAX_CORRELATION = 0.90  # Era 0.85

# Opci√≥n 2: Aceptar menos caracter√≠sticas
# La validaci√≥n de 06-C ya garantiza que son suficientes
```

### **Performance Pobre en Todos los Subsets**

Si todos los subsets dan ROC-AUC < 0.70:

1. **Verifica los datos de entrada**:
   ```bash
   # Distribuci√≥n de clases balanceada?
   python -c "import pandas as pd; df=pd.read_csv('input.csv'); print(df['label'].value_counts())"
   ```

2. **Revisa la selecci√≥n de caracter√≠sticas en 06-C**:
   - ¬øPas√≥ la validaci√≥n?
   - ¬øSilhouette > 0.3?
   - ¬øFisher ratio > 1.5?

3. **Considera ajustar umbral Cohen's d en 06-C**:
   - d ‚â• 0.2 es permisivo (m√°s caracter√≠sticas)
   - d ‚â• 0.5 es restrictivo (menos caracter√≠sticas)

---

## üìö Referencias

- **M√≥dulo 06-C**: Documentaci√≥n completa del proceso de selecci√≥n de caracter√≠sticas
- **Documentaci√≥n de configuraci√≥n de modelos**: Ver `config.py` para par√°metros de cada clasificador

---

## üéì Ejemplo Completo

```bash
# 1. Generar descriptores (si no existen)
cd 05_Texture_Descriptors_m7_tau9
python main.py

# 2. Seleccionar caracter√≠sticas rigorosamente
cd ../06-C_Feature_Selection
python main.py

# Output:
# ‚úì 15 caracter√≠sticas seleccionadas
# ‚úì Validaci√≥n PASADA (Silhouette=0.52, Fisher=2.3)
# ‚úì JSON generado: output/feature_ranking.json

# 3. Evaluar todos los subsets autom√°ticamente
cd ../07-C_Classification
python main.py

# Output:
# ‚úì Caracter√≠sticas cargadas: 15
# ‚úì Subsets evaluados: 6 (top_5, top_10, all_selected, lbp_only, stat_only, wavelet_only)
# ‚úì Modelos entrenados por subset: 8
# ‚úì Total entrenamientos: 48
#
# üèÜ MEJOR CONFIGURACI√ìN GLOBAL:
#   Subset: top_10
#   Modelo: Random Forest
#   F1-Score: 0.8185
#   ROC-AUC: 0.9005
```

**Todo el proceso es autom√°tico, reproducible y cient√≠ficamente defendible.**

---

## üî¨ Resultados Experimentales: Justificaci√≥n de Cohen's d ‚â• 0.2

Este m√≥dulo utiliza caracter√≠sticas seleccionadas con **Cohen's d ‚â• 0.2** (efecto peque√±o+).

**Experimento controlado** (mismo dataset, random_state=42):

| Pipeline | Umbral Cohen's d | Caracter√≠sticas | Mejor Config | F1-Score | ROC-AUC | Validaci√≥n |
|----------|------------------|-----------------|--------------|----------|---------|------------|
| **06-C/07-C** | **d ‚â• 0.2** | 15 ‚Üí **TOP_10** | Random Forest | **0.8185** | **0.9005** | ‚úì APROBADA |
| 06-D/07-D | d ‚â• 0.5 | 5 | SVM | 0.8041 | 0.7781 | ‚úó FALLIDA |

**Conclusi√≥n**: d ‚â• 0.2 ofrece mejor generalizaci√≥n (ROC-AUC +15.7%) y validaci√≥n aprobada.

Ver documentaci√≥n detallada en: `06-C_Feature_Selection/docs/JUSTIFICACION_COHENS_D_0.2.md`

---

**Generado autom√°ticamente para el m√≥dulo 07-C**
**√öltima actualizaci√≥n**: 2025-12-06
