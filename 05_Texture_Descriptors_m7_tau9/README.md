# MÃ³dulo 05: ExtracciÃ³n de Descriptores de Textura (m=7, Ï„=9)

## DescripciÃ³n

Este mÃ³dulo analiza los Recurrence Plots generados con parÃ¡metros **m=7** y **Ï„=9** (mÃ³dulo 04_RP_Generator_m7_tau9) y extrae caracterÃ­sticas de textura multiescala para la clasificaciÃ³n binaria de voces normales y patolÃ³gicas.

## Dataset Procesado

- **Total de RPs**: 440 (239 Normal, 201 PatolÃ³gica)
- **ParÃ¡metros RP**: m=7, Ï„=9, Îµ=10%
- **TamaÃ±o de imÃ¡genes**: ~25,000 Ã— 25,000 pÃ­xeles
- **Formato**: PNG, escala de grises

## Descriptores Implementados

El mÃ³dulo extrae **181 caracterÃ­sticas** de 5 familias de descriptores:

### ğŸ“Š Descriptores Activos (Usados en AnÃ¡lisis Final)

1. **GLCM (Gray-Level Co-occurrence Matrix)** - 6 caracterÃ­sticas
   - Propiedades de co-ocurrencia espacial
   - Distancia: [1], Ãngulos: [0Â°, 45Â°, 90Â°, 135Â°]
   - Propiedades: contraste, disimilaridad, homogeneidad, energÃ­a, correlaciÃ³n, ASM
   - Niveles de gris: 256

2. **LBP (Local Binary Patterns)** - 14 caracterÃ­sticas
   - Patrones binarios locales uniformes
   - Radio: [1], Puntos: [4]
   - MÃ©todo: 'uniform' (patrones con â‰¤2 transiciones)
   - CaracterÃ­sticas: histogramas, ratios, entropÃ­a, uniformidad

3. **Wavelet** - 65 caracterÃ­sticas
   - DescomposiciÃ³n multi-escala (db4, 3 niveles)
   - CaracterÃ­sticas: energÃ­a, entropÃ­a, media, desviaciÃ³n estÃ¡ndar
   - Subbandas: AproximaciÃ³n (A) + Detalles (H, V, D) por nivel
   - Ratios direccionales: horizontal, vertical, diagonal

4. **RQA (Recurrence Quantification Analysis)** - 10 caracterÃ­sticas
   - CuantificaciÃ³n de recurrencia dinÃ¡mica
   - MÃ©tricas: RR, DET, LAM, L_max, L_mean, V_max, V_mean, ENTR, DIV, TT
   - Epsilon: adaptativo (percentil 10)
   - Longitud mÃ­nima de lÃ­nea: 2

5. **Statistical** - 86 caracterÃ­sticas
   - Momentos estadÃ­sticos: media, std, skewness, kurtosis
   - Percentiles: [10, 25, 50, 75, 90]
   - Histogramas: 64 bins
   - EntropÃ­a de Shannon

### ğŸ”’ Descriptores Disponibles pero NO Usados

- **Gabor**: Calculado pero excluido del anÃ¡lisis final
- **Tamura**: Calculado pero excluido del anÃ¡lisis final

## CaracterÃ­sticas del Sistema

### ğŸ”§ Sistema Modular e Incremental
- Cada descriptor se calcula y almacena **independientemente**
- AÃ±ade nuevos descriptores **sin recalcular** los existentes
- ReutilizaciÃ³n automÃ¡tica si la configuraciÃ³n no cambiÃ³
- Sistema de checkpoints parciales para procesos interrumpibles

### âš™ï¸ ConfiguraciÃ³n Centralizada
- ConfiguraciÃ³n en `config.py` tiene prioridad sobre defaults
- Optimizado especÃ­ficamente para Recurrence Plots
- Sistema de detecciÃ³n de cambios mediante hash de configuraciÃ³n

## Uso

### LÃ­nea de Comandos

```bash
# Calcular todos los descriptores habilitados en config.py
python main.py

# Solo descriptores especÃ­ficos
python main.py --descriptors glcm lbp wavelet rqa statistical

# Calcular solo descriptores faltantes (incremental)
python main.py --descriptors glcm lbp wavelet

# Ver estado del sistema
python main.py --checkpoint-info

# Interfaz grÃ¡fica (si disponible)
python main.py --gui
```

### CombinaciÃ³n de Descriptores

Para generar el archivo combinado usado en el anÃ¡lisis:

```bash
python main.py --descriptors glcm lbp wavelet rqa statistical
```

Esto genera: `combined_glcm_lbp_wavelet_rqa_statistical_YYYYMMDD_HHMMSS.csv`

## Estructura de Salida

```
output/
â”œâ”€â”€ features/
â”‚   â”œâ”€â”€ by_descriptor/                   # CaracterÃ­sticas por descriptor
â”‚   â”‚   â”œâ”€â”€ glcm/
â”‚   â”‚   â”‚   â”œâ”€â”€ features.csv            # 440 muestras Ã— 6 caracterÃ­sticas
â”‚   â”‚   â”‚   â”œâ”€â”€ metadata.json           # ConfiguraciÃ³n y estadÃ­sticas
â”‚   â”‚   â”‚   â””â”€â”€ partial_checkpoint.json # Checkpoint (si existe)
â”‚   â”‚   â”œâ”€â”€ lbp/
â”‚   â”‚   â”‚   â””â”€â”€ features.csv            # 440 muestras Ã— 14 caracterÃ­sticas
â”‚   â”‚   â”œâ”€â”€ wavelet/
â”‚   â”‚   â”‚   â””â”€â”€ features.csv            # 440 muestras Ã— 65 caracterÃ­sticas
â”‚   â”‚   â”œâ”€â”€ rqa/
â”‚   â”‚   â”‚   â””â”€â”€ features.csv            # 440 muestras Ã— 10 caracterÃ­sticas
â”‚   â”‚   â”œâ”€â”€ statistical/
â”‚   â”‚   â”‚   â””â”€â”€ features.csv            # 440 muestras Ã— 86 caracterÃ­sticas
â”‚   â”‚   â”œâ”€â”€ gabor/                      # NO usado en anÃ¡lisis final, por cuestiÃ³n de recurso computacional
â”‚   â”‚   â””â”€â”€ tamura/                     # NO usado en anÃ¡lisis final, por cuestiÃ³n de recurso computacional
â”‚   â”œâ”€â”€ combined/                        # CaracterÃ­sticas combinadas
â”‚   â”‚   â””â”€â”€ combined_glcm_lbp_wavelet_rqa_statistical_20251204_173601.csv
â”‚   â””â”€â”€ manifest.json                    # Estado global del sistema
â””â”€â”€ checkpoints/                         # Checkpoints de procesamiento
```

## Dataset Final Generado

**Archivo**: `combined_glcm_lbp_wavelet_rqa_statistical_20251204_173601.csv`

- **Dimensiones**: 440 muestras Ã— 181 caracterÃ­sticas
- **DistribuciÃ³n de clases**:
  - Normal: 239 (54.3%)
  - PatolÃ³gica: 201 (45.7%)
- **CaracterÃ­sticas por descriptor**:
  - GLCM: 6 (3.3%)
  - LBP: 14 (7.7%)
  - Wavelet: 65 (35.9%)
  - RQA: 10 (5.5%)
  - Statistical: 86 (47.5%)

## Sistema de Checkpoints

El mÃ³dulo implementa un sistema robusto de checkpoints:

### Niveles de Checkpoint

1. **manifest.json**: Rastrea descriptores calculados y estado global
2. **Checkpoints parciales**: Guardan progreso cada N imÃ¡genes (configurable)
3. **DetecciÃ³n de cambios**: Recalcula automÃ¡ticamente si cambiÃ³ la configuraciÃ³n

### ConfiguraciÃ³n de Checkpoints

```python
CHECKPOINT_BATCH_SIZE = 5              # Guardar cada 5 imÃ¡genes
ENABLE_PARTIAL_CHECKPOINTS = True      # Habilitar checkpoints granulares
CHECKPOINT_FREQUENCY = 10              # Frecuencia global
```

## Flujo de Trabajo

### Primera EjecuciÃ³n
1. Lee RPs de `../04_RP_Generator_m7_tau9/output/Recurrence_Plots/`
2. Calcula descriptores habilitados en `config.py`
3. Guarda CSVs individuales en `by_descriptor/`
4. Genera manifest.json con metadata

### Ejecuciones Posteriores
1. Verifica manifest.json
2. Compara hash de configuraciÃ³n
3. **Si NO cambiÃ³**: Reutiliza descriptores existentes
4. **Si cambiÃ³**: Recalcula solo el descriptor modificado
5. **Si hay nuevas imÃ¡genes**: Procesa solo las nuevas (incremental)

### GeneraciÃ³n de Combinado
1. Lee CSVs individuales de `by_descriptor/`
2. Verifica mismo orden de muestras
3. Concatena horizontalmente
4. Guarda en `combined/` con timestamp

## ConfiguraciÃ³n de Procesamiento

### ImÃ¡genes
```python
IMAGE_MIN_SIZE = (2000, 2000)      # TamaÃ±o mÃ­nimo aceptado
IMAGE_MAX_SIZE = (25000, 25000)    # TamaÃ±o mÃ¡ximo (RPs ~25,000Ã—25,000)
IMAGE_TARGET_DTYPE = 'uint8'       # Tipo de datos
IMAGE_NORMALIZE_RANGE = (0, 255)   # Rango de normalizaciÃ³n
```

### ParalelizaciÃ³n
```python
ENABLE_PARALLEL = True             # Activar procesamiento paralelo
N_JOBS = -1                        # Usar todos los cores disponibles
```

## IntegraciÃ³n con Pipeline

### Entrada
- **Fuente**: `../04_RP_Generator_m7_tau9/output/Recurrence_Plots/`
- **Archivos**: `Normal/*.png`, `Pathol/*.png`
- **Total**: 440 RPs (239 + 201)

### Salida
- **Destino**: `../06-C_Feature_Selection/`
- **Archivo**: `combined_glcm_lbp_wavelet_rqa_statistical_20251204_173601.csv`
- **Formato**: CSV con columnas [filename, label, feature_1, ..., feature_181]

## Resultados del AnÃ¡lisis

El dataset de 181 caracterÃ­sticas generado por este mÃ³dulo fue procesado en los mÃ³dulos posteriores:

- **06-C_Feature_Selection**: ReducciÃ³n a 15 caracterÃ­sticas Ã³ptimas
- **07-C_Classification**: ClasificaciÃ³n con Random Forest (79.55% accuracy, 90.47% AUC)

### Top 5 CaracterÃ­sticas MÃ¡s Importantes (Random Forest)

1. `lbp_hist_bin_5_r1_p4` (18.5% importancia)
2. `stat_hist_bin_0` (14.2%)
3. `wavelet_energy_detail_H_L1` (11.9%)
4. `rqa_LAM` (9.8%)
5. `lbp_nonuniform_ratio_r1_p4` (8.9%)

## Notas Importantes

- âœ… El sistema es **interrumpible** y **reanudable** en cualquier momento
- âœ… Los descriptores se calculan de forma **independiente** y **paralela**
- âœ… La configuraciÃ³n en `config.py` tiene **prioridad absoluta**
- âœ… Compatible con **procesamiento incremental** (solo nuevas imÃ¡genes)
- âš ï¸  Gabor y Tamura estÃ¡n disponibles pero **NO se usan** en el pipeline final
- âœ…  Los archivos deben estar en el **mismo orden** en todos los CSVs para combinar


## Referencias

- **MÃ³dulo anterior**: `04_RP_m7_tau9` (GeneraciÃ³n de Recurrence Plots)
- **MÃ³dulo siguiente**: `06-C_Feature_Selection` (SelecciÃ³n de CaracterÃ­sticas)
- **Resultados finales**: Ver `RESULTADOS_PIPELINE_m7_tau9.md` en la raÃ­z del proyecto
