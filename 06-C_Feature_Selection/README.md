# MÃ³dulo 06-C: SelecciÃ³n Rigurosa de CaracterÃ­sticas

## ğŸ“‹ DescripciÃ³n

Este mÃ³dulo implementa un **proceso cientÃ­ficamente defendible de 5 fases** para seleccionar caracterÃ­sticas Ã³ptimas para clasificaciÃ³n de voces normales vs patolÃ³gicas.

**06-C genera automÃ¡ticamente un JSON** con las caracterÃ­sticas seleccionadas que el mÃ³dulo 07-C consume sin intervenciÃ³n manual, permitiendo un pipeline completamente automatizado y reproducible.

## ğŸ¯ Objetivo

Eliminar la **desconexiÃ³n manual** entre anÃ¡lisis (mÃ³dulo 06) y clasificaciÃ³n (mÃ³dulo 07), implementando un pipeline automÃ¡tico y reproducible basado en:

1. **Significancia estadÃ­stica** (p-value)
2. **Relevancia prÃ¡ctica** (Cohen's d)
3. **Poder discriminativo** (F-Score + Mutual Information)
4. **EliminaciÃ³n de redundancia** (correlaciÃ³n)
5. **ValidaciÃ³n de separabilidad** (PCA, Silhouette, Fisher)

---

## ğŸ”¬ Las 5 Fases del Pipeline

### **Fase 1: Filtrado por Significancia EstadÃ­stica**

**Objetivo**: Eliminar caracterÃ­sticas cuyas diferencias entre clases podrÃ­an ser azar.

**MÃ©todo**: F-statistic ANOVA (sklearn.feature_selection.f_classif)

**Criterio**:
```python
p-value < Î± = 0.05
```

**InterpretaciÃ³n**:
- **p < 0.05**: Hay evidencia estadÃ­stica suficiente de que la caracterÃ­stica discrimina
- **p â‰¥ 0.05**: No hay evidencia (diferencia podrÃ­a ser azar) â†’ **RECHAZADA**

**Ejemplo**:
```
CaracterÃ­stica A: F=8.5, p=0.003  â†’ âœ“ Pasa (evidencia estadÃ­stica)
CaracterÃ­stica B: F=2.1, p=0.082  â†’ âœ— Rechazada (sin evidencia)
```

---

### **Fase 2: Filtrado por Relevancia PrÃ¡ctica**

**Objetivo**: Eliminar caracterÃ­sticas estadÃ­sticamente significativas pero con efecto trivial.

**MÃ©todo**: Cohen's d (tamaÃ±o del efecto)

**FÃ³rmula**:
```
Cohen's d = (Î¼â‚ - Î¼â‚‚) / Ïƒ_pooled

donde Ïƒ_pooled = âˆš[((nâ‚-1)Ïƒâ‚Â² + (nâ‚‚-1)Ïƒâ‚‚Â²) / (nâ‚+nâ‚‚-2)]
```

**Criterio**:
```python
|Cohen's d| â‰¥ 0.2  (efecto pequeÃ±o o superior)
```

**InterpretaciÃ³n** (Cohen, 1988):
- **|d| < 0.2**: Efecto **trivial** (despreciable) â†’ **RECHAZADA**
- **0.2 â‰¤ |d| < 0.5**: Efecto **pequeÃ±o** (aceptable) â†’ âœ“ **ACEPTADA**
- **0.5 â‰¤ |d| < 0.8**: Efecto **mediano** (ideal) â†’ âœ“ **ACEPTADA**
- **|d| â‰¥ 0.8**: Efecto **grande** (ideal) â†’ âœ“ **ACEPTADA**

**Â¿Por QuÃ© Es Importante?**

```
Ejemplo problemÃ¡tico:
- CaracterÃ­stica: lbp_feature_X
- Normal:     Î¼=0.023, Ïƒ=0.008
- PatolÃ³gica: Î¼=0.025, Ïƒ=0.008
- Diferencia: 0.002 (2 milÃ©simas)
- Con n=500: p=0.003 (significativo âœ“)
- Cohen's d: 0.25 (efecto pequeÃ±o âœ—)

ConclusiÃ³n: Diferencia es REAL (no azar), pero TAN PEQUEÃ‘A que:
  1. El clasificador tendrÃ¡ dificultad usÃ¡ndola
  2. Es sensible a ruido de mediciÃ³n
  3. No aporta poder discriminativo prÃ¡ctico
```

---

### **Fase 3: Ranking por Poder Discriminativo Combinado**

**Objetivo**: Rankear caracterÃ­sticas considerando relaciones lineales Y no lineales.

**MÃ©todos**:
1. **F-Score ANOVA**: Captura diferencias de medias (lineal)
2. **Mutual Information**: Captura dependencias no lineales

**Score Combinado**:
```python
# Normalizar ambos a [0, 1]
F_norm = (F - F_min) / (F_max - F_min)
MI_norm = (MI - MI_min) / (MI_max - MI_min)

# Score combinado (70% F-Score, 30% MI)
Combined = 0.7 Ã— F_norm + 0.3 Ã— MI_norm
```

**JustificaciÃ³n de pesos**:
- **70% F-Score**: CaracterÃ­sticas de textura suelen tener relaciones lineales con la clase
- **30% MI**: Captura relaciones no lineales que F-Score pierde
- Ajustable segÃºn dominio (usa 50-50 si esperas fuertes no linealidades)

---

### **Fase 4: EliminaciÃ³n de Redundancia** âš ï¸ **CRÃTICO**

**Objetivo**: Evitar multicolinealidad seleccionando caracterÃ­sticas complementarias.

**Algoritmo Greedy**:
```python
selected = []
for feature in ranking (ordenado por Combined Score):
    # Calcular correlaciÃ³n con caracterÃ­sticas ya seleccionadas
    max_corr = max(|r(feature, s)| for s in selected)

    if max_corr < 0.85:  # Threshold
        selected.append(feature)
    else:
        RECHAZAR (redundante)
```

**Criterio**:
```python
|r| < 0.85  (correlaciÃ³n de Pearson)
```

**JustificaciÃ³n (VIF - Variance Inflation Factor)**:
```
VIF = 1 / (1 - rÂ²)

Con r=0.85: VIF = 1/(1-0.72) = 3.57  (tolerable, lÃ­mite es ~5)
Con r=0.90: VIF = 1/(1-0.81) = 5.26  (problemÃ¡tico)

Threshold 0.85 = Balance entre diversidad y complementariedad
```

**Â¿Por QuÃ© Es CrÃ­tico?**

```
Ejemplo de problema de redundancia:
- lbp_hist_bin_5_r1_p4   F=62.6, Combined=0.90
- lbp_hist_bin_0_r1_p4   F=56.1, Combined=0.86
- CorrelaciÃ³n entre ellas: r=0.97 (muy alta!)

Sin Fase 4:
  â†’ Seleccionas AMBAS
  â†’ Aportan esencialmente la misma informaciÃ³n
  â†’ Multicolinealidad en el modelo
  â†’ Desperdicio de 1 slot de tus 15 caracterÃ­sticas

Con Fase 4:
  â†’ Seleccionas lbp_hist_bin_5_r1_p4 (rank 1)
  â†’ Rechazas lbp_hist_bin_0_r1_p4 (redundante con anterior)
  â†’ Usas ese slot para una caracterÃ­stica complementaria
```

---

### **Fase 5: ValidaciÃ³n de Separabilidad**

**Objetivo**: Verificar que el subset seleccionado realmente separa bien las clases.

**MÃ©tricas**:

1. **Varianza Explicada por PCA**
   ```python
   PCA con k componentes â†’ Î£ explained_variance_ratio
   Criterio: > 80%
   ```
   InterpretaciÃ³n: Las caracterÃ­sticas capturan suficiente informaciÃ³n

2. **Silhouette Score**
   ```python
   Silhouette = (b - a) / max(a, b)
   donde:
     a = distancia promedio intra-cluster
     b = distancia promedio inter-cluster

   Criterio: > 0.3 (aceptable), > 0.5 (bueno), > 0.7 (excelente)
   ```
   InterpretaciÃ³n: QuÃ© tan bien separadas estÃ¡n las clases

3. **Fisher Ratio**
   ```python
   Fisher = distancia_inter_clase / distancia_intra_clase
   Criterio: > 1.5
   ```
   InterpretaciÃ³n: Clases mÃ¡s separadas que dispersas internamente

---

## ğŸš€ Uso del MÃ³dulo

### **InstalaciÃ³n de Dependencias**

```bash
pip install pandas numpy scikit-learn scipy
```

### **EjecuciÃ³n**

```bash
# Desde la raÃ­z del proyecto
cd 06-C_Feature_Selection

# Pipeline completo
python main.py

# Con logging detallado
python main.py --verbose

# Especificar archivo de entrada
python main.py --input /path/to/features.csv
```

### **Salidas Generadas**

```
06-C_Feature_Selection/output/
â”œâ”€â”€ feature_ranking.json          # â† USADO POR 07-C AUTOMÃTICAMENTE
â”œâ”€â”€ selection_report.md           # Reporte detallado en Markdown
â””â”€â”€ feature_selection.log         # Log completo del proceso
```

---

## ğŸ“Š Formato del JSON de Salida

```json
{
  "metadata": {
    "timestamp": "2025-08-12T17:30:00",
    "pipeline_version": "1.0.0"
  },
  "configuration": {
    "alpha": 0.05,
    "min_cohens_d": 0.5,
    "weight_f_score": 0.7,
    "weight_mi": 0.3,
    "max_correlation": 0.85,
    "target_n_features": 15
  },
  "selected_features": [
    {
      "rank": 1,
      "name": "lbp_hist_bin_5_r1_p4",
      "descriptor": "lbp",
      "f_score": 62.600,
      "p_value": 2.09e-14,
      "cohens_d": -0.757,
      "effect_size": "medium",
      "mi_score": 0.107,
      "combined_score": 0.900,
      "justification": "altamente significativa (p<0.001), efecto medium (|d|=0.76), alto poder discriminativo"
    },
    ...
  ],
  "validation": {
    "pca_variance_explained": 0.87,
    "silhouette_score": 0.52,
    "fisher_ratio": 2.3,
    "validation_passed": true
  }
}
```

---

## ğŸ”— ConexiÃ³n con MÃ³dulo 07-C

El mÃ³dulo **07-C** consume automÃ¡ticamente el JSON:

```python
# 07-C_Classification/config.py

def load_selected_features():
    """Carga automÃ¡ticamente desde 06-C."""
    with open('06-C_Feature_Selection/output/feature_ranking.json') as f:
        data = json.load(f)

    return [feat['name'] for feat in data['selected_features']]

# Carga automÃ¡tica al importar config
SELECTED_FEATURES = load_selected_features()
```

**No mÃ¡s configuraciÃ³n manual. Todo automÃ¡tico y reproducible.**

---

## ğŸ“ˆ ParÃ¡metros Configurables

En `config.py`:

| ParÃ¡metro | Valor Default | DescripciÃ³n |
|-----------|---------------|-------------|
| `ALPHA` | 0.05 | Nivel de significancia (95% confianza) |
| `MIN_COHENS_D` | 0.2 | Efecto mÃ­nimo (pequeÃ±o+) |
| `WEIGHT_F_SCORE` | 0.7 | Peso F-Score en ranking |
| `WEIGHT_MI_SCORE` | 0.3 | Peso MI en ranking |
| `MAX_CORRELATION` | 0.85 | Threshold redundancia |
| `TARGET_N_FEATURES` | 15 | Objetivo de caracterÃ­sticas |
| `MIN_PCA_VARIANCE` | 0.80 | MÃ­nima varianza explicada |
| `MIN_SILHOUETTE_SCORE` | 0.30 | MÃ­nima separabilidad |
| `MIN_FISHER_RATIO` | 1.5 | MÃ­nimo ratio inter/intra |

---

## ğŸ“š Referencias CientÃ­ficas

1. **Fisher, R.A. (1925)**. *Statistical Methods for Research Workers*.
   - Fundamento del test F-ANOVA

2. **Cohen, J. (1988)**. *Statistical Power Analysis for the Behavioral Sciences (2nd ed.)*.
   - DefiniciÃ³n de tamaÃ±os de efecto (Cohen's d)

3. **Kutner et al. (2004)**. *Applied Linear Statistical Models*.
   - Variance Inflation Factor (VIF) y multicolinealidad

4. **Rousseeuw, P.J. (1987)**. *Silhouettes: A graphical aid to the interpretation and validation of cluster analysis*.
   - Silhouette score para validaciÃ³n

---

## âš™ï¸ Flujo Completo del Pipeline

```
ENTRADA: features.csv (181 caracterÃ­sticas)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FASE 1: Significancia EstadÃ­stica          â”‚
â”‚ Filtro: p < 0.05                            â”‚
â”‚ Output: 79 caracterÃ­sticas                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FASE 2: Relevancia PrÃ¡ctica                â”‚
â”‚ Filtro: |Cohen's d| â‰¥ 0.2                   â”‚
â”‚ Output: 71 caracterÃ­sticas                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FASE 3: Ranking Discriminativo              â”‚
â”‚ Score: 0.7Ã—F_norm + 0.3Ã—MI_norm             â”‚
â”‚ Output: CaracterÃ­sticas rankeadas           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FASE 4: EliminaciÃ³n de Redundancia          â”‚
â”‚ Filtro: |r| < 0.85 (greedy)                 â”‚
â”‚ Output: 15 caracterÃ­sticas                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FASE 5: ValidaciÃ³n de Separabilidad         â”‚
â”‚ Verifica: PCA > 80%, Silhouette > 0.3       â”‚
â”‚ Output: feature_ranking.json                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
SALIDA: 15 caracterÃ­sticas optimizadas
        (listas para clasificaciÃ³n en 07-C)
```

---

## ğŸ“ CaracterÃ­sticas Principales del Pipeline

| Aspecto | ImplementaciÃ³n en 06-C |
|---------|------------------------|
| **Significancia estadÃ­stica** | âœ“ Filtro por p-value < 0.05 (F-statistic ANOVA) |
| **Relevancia prÃ¡ctica** | âœ“ Filtro por Cohen's d â‰¥ 0.2 (efecto pequeÃ±o+) |
| **Poder discriminativo** | âœ“ Ranking combinado: 70% F-Score + 30% Mutual Information |
| **EliminaciÃ³n de redundancia** | âœ“ Filtro activo por correlaciÃ³n (r < 0.85, VIF < 3.6) |
| **ValidaciÃ³n de separabilidad** | âœ“ MÃ©tricas cuantitativas (PCA variance, Silhouette, Fisher ratio) |
| **Salida** | âœ“ JSON estructurado con metadata completa + Reporte Markdown |
| **ConexiÃ³n con clasificaciÃ³n** | âœ“ IntegraciÃ³n automÃ¡tica con mÃ³dulo 07-C (sin configuraciÃ³n manual) |
| **Reproducibilidad** | âœ“ Proceso completamente automatizado (random_state, thresholds fijos) |
| **JustificaciÃ³n cientÃ­fica** | âœ“ MÃ©tricas cuantificables para cada caracterÃ­stica seleccionada |

---

## ğŸ” Ejemplo de EjecuciÃ³n

```bash
$ python main.py

================================================================================
MÃ“DULO 06-C: SELECCIÃ“N RIGUROSA DE CARACTERÃSTICAS
================================================================================

âœ“ CaracterÃ­sticas cargadas automÃ¡ticamente desde 06-C:
  - Total: 181 caracterÃ­sticas iniciales

================================================================================
FASE 1: FILTRADO POR SIGNIFICANCIA ESTADÃSTICA
================================================================================
Total caracterÃ­sticas: 181
âœ“ Significativas (p < 0.05): 79
âœ— Rechazadas (p â‰¥ 0.05): 102

================================================================================
FASE 2: FILTRADO POR RELEVANCIA PRÃCTICA (COHEN'S D)
================================================================================
Entrada: 79 caracterÃ­sticas
âœ“ Relevantes (|d| â‰¥ 0.2): 71
âœ— Rechazadas (|d| < 0.2): 8

DistribuciÃ³n de tamaÃ±os de efecto:
  - small: 58
  - medium: 13

================================================================================
FASE 3: RANKING POR PODER DISCRIMINATIVO
================================================================================
Top 10 caracterÃ­sticas:
  1. lbp_hist_bin_5_r1_p4                 | Combined=0.900 | F= 62.60 | MI=0.107
  2. lbp_hist_bin_0_r1_p4                 | Combined=0.858 | F= 56.09 | MI=0.103
  ...

================================================================================
FASE 4: ELIMINACIÃ“N DE REDUNDANCIA
================================================================================
âœ“ lbp_hist_bin_5_r1_p4                   | Primera caracterÃ­stica
âœ— lbp_hist_bin_0_r1_p4                   | REDUNDANTE: r=0.97 con lbp_hist_bin_5_r1_p4
âœ“ stat_hist_bin_0                        | max_r=0.38 con lbp_hist_bin_5_r1_p4
...

CaracterÃ­sticas seleccionadas: 15/15

================================================================================
FASE 5: VALIDACIÃ“N DE SEPARABILIDAD
================================================================================
  PCA varianza: 87% (mÃ­n: 80%)
  Silhouette: 0.52 (Buena separabilidad)
  Fisher ratio: 2.3 (mÃ­n: 1.5)

âœ“ VALIDACIÃ“N EXITOSA: Subset de caracterÃ­sticas es apropiado

================================================================================
âœ“ PIPELINE COMPLETADO EXITOSAMENTE
================================================================================

Archivos generados:
  - JSON: output/feature_ranking.json
  - Markdown: output/selection_report.md
  - Log: feature_selection.log
```

---

## ğŸ’¡ Preguntas Frecuentes

### Â¿Por quÃ© necesito ambos Cohen's d y p-value?

- **p-value**: "Â¿La diferencia es real o azar?" (significancia **estadÃ­stica**)
- **Cohen's d**: "Â¿La diferencia importa en la prÃ¡ctica?" (significancia **prÃ¡ctica**)

Con muestras grandes, diferencias microscÃ³picas dan p < 0.05 pero d < 0.2 (efecto trivial). Necesitas **ambos**.

### Â¿Por quÃ© 70% F-Score y 30% MI?

F-Score captura relaciones lineales (diferencias de medias). MI captura relaciones no lineales. Las caracterÃ­sticas de textura suelen ser lineales, por eso favorecemos F-Score. Ajusta los pesos si tu dominio es diferente.

### Â¿QuÃ© pasa si no alcanzo 15 caracterÃ­sticas?

Si despuÃ©s de eliminar redundancia tienes menos de 15, el algoritmo se detiene. Puedes relajar `MAX_CORRELATION` a 0.90 en config.py.

### Â¿Puedo usar un CSV diferente?

SÃ­. Especifica con `--input`:
```bash
python main.py --input /path/to/other_features.csv
```

---

## ğŸ› ï¸ Troubleshooting

**Error: "Archivo de entrada no encontrado"**
```bash
# SoluciÃ³n: Ejecuta primero el mÃ³dulo 05
cd 05_Texture_Descriptors
python main.py
```

**Warning: "ValidaciÃ³n FALLIDA"**
```
Significa que el subset no cumple todos los criterios (PCA < 80%, Silhouette < 0.3, o Fisher < 1.5).

Soluciones:
1. Relajar MIN_COHENS_D a 0.4 para incluir mÃ¡s caracterÃ­sticas
2. Relajar MAX_CORRELATION a 0.90 para permitir mÃ¡s redundancia
3. Revisar si los datos tienen suficiente poder discriminativo
```

---

**Generado automÃ¡ticamente por el pipeline 06-C**
